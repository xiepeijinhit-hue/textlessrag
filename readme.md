



# <div align="center">TextLessRAG: End-to-end Visual Document RAG by Speech without Text<div>

<div align="center">
<!-- <h1>A Multi-round Multi-modal Reinforcement Learning Framework</h1> -->
<p><strong>A end2end OCR & ASR free multimodal retrieval-augmented generation pipeline </strong></p>
<a href="https://arxiv.org/pdf/2505.22019" target="_blank"><img src=https://img.shields.io/badge/Paper-arXiv-red></a>
<a href='https://huggingface.co/datasets/hit12345/textlessrag/tree/main'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Datasets-green'></a>
<!-- <a href="https://huggingface.co/autumncc/Qwen2.5-VL-7B-VRAG" target="_blank"><img src=https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-data-blue></a> -->
</div>


## ğŸ”¥ News
- ğŸ‰ xxx.
- ğŸ‰ xxx.
- ğŸ‰ xxx. Welcome to use!
- â³ The project is still under ongoing development, and the training code will be available soon~
<!-- - âŒ›ï¸ Training code will be released soon. -->
<!-- - ğŸ‰ Our framework integrates various embedding models, enabling you to create your own retriever.
- ğŸ‰ We have released the ViDoSeek dataset, which is suitable for Retrieval-augmented Generation in the large visually rich document collection. -->



## Dataset
We construct the first Chinese Visual Doc RAG Dataset -- ChineseDocRAG(CDR)
Domains world cloud:

<img width="3000" height="1500" alt="wordcloud" src="https://github.com/user-attachments/assets/556408ce-8d54-41e2-9bca-a8494a8879ee" />






